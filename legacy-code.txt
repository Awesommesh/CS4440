import nltk 
import requests
from nltk.corpus import wordnet
import re 


#THIS DOES GOOD

words = []

#human readable query -> wnid
query = input("Enter your search query: ")
#searching from words.txt
synset = open("words.txt","r", 1)
synset.seek(0)
for line in synset:
    if (query.lower() in line.lower()):
        wnid = line[0:9]
        words.append(wnid)
synset.close()


#get children wnid
payload = {'full': '1', 'wnid': words[0]}
r = requests.get('http://www.image-net.org/api/text/wordnet.structure.hyponym', params = payload)
# print(r.url)
page_contents = r.text #string
# print (type(page_contents))
page_contents_to_list = re.split(r'[\n\r]\s*', page_contents)
words.append(page_contents_to_list[0]) #html page formatted weird
for id in page_contents_to_list[1:]:
    words.append(id[1:10])
del words[-1] #again, weird '' at end of list


print (words)


























-------------------------------------------------------

import nltk 
from nltk.corpus import wordnet 

query = input("Enter your search query: ")

#SEARCHING FROM WORDS.TXT (entire imagenet)
#searching from words.txt
synset = open("words.txt","r", 1)
synset.seek(0)
for line in synset:
    stripped_line = line.strip()
    if (query.lower() in stripped_line.lower()):
        words += stripped_line.split(",")
synset.close()
print (words)

















-------------------------------------

#searching from wordnet 
# syn = wordnet.synsets(query) 
# print(nltk.word_tokenize(syn[0].definition()))

words = []
#searching from synset.txt
synset = open("synset.txt","r", 1)
synset.seek(0)
print (synset.read().count('\n')) #counting newlines
synset.seek(0)
for line in synset:
    stripped_line = line.strip()
    if (query.lower() in stripped_line.lower()):
        words += stripped_line.split(",")
        break
synset.close()
print (words)

#rough
# synset = open("synset.txt","r", 1)
# x = synset.read().find(query) #gives starting index, without newlines

# synset.seek(0)
# c = synset.read().count('\n', 0, x) #counting newlines

# synset.seek(x+c-10, 0)  
# line = synset.readline(100)
# words = line.split(",")   
# # words = nltk.word_tokenize(line)
# print (words)

# synset.close()